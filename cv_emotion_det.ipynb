{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_6 (Conv2D)            (None, 48, 48, 64)        640       \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nactivation_8 (Activation)    (None, 48, 48, 64)        0         \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 24, 24, 64)        0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 24, 24, 128)       73856     \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nactivation_9 (Activation)    (None, 24, 24, 128)       0         \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 12, 12, 128)       0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 12, 12, 256)       295168    \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 12, 12, 256)       1024      \n_________________________________________________________________\nactivation_10 (Activation)   (None, 12, 12, 256)       0         \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 512)               4719104   \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 512)               2048      \n_________________________________________________________________\nactivation_11 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 6)                 3078      \n=================================================================\nTotal params: 5,095,686\nTrainable params: 5,093,766\nNon-trainable params: 1,920\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('model/checkpoint.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "frames = 0\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "face_cascade.load('haarcascade_frontalface_default.xml')\n",
    "label_map = ['Anger', 'Neutral', 'Fear', 'Happy', 'Sad', 'Surprise']\n",
    "\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, scaleFactor=1.05, minNeighbors=5)\n",
    "    for x, y, w, h in faces:\n",
    "        if frames % 5 == 0:\n",
    "            face = frame[y:y+h, x:x+w,]\n",
    "            face_g = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            face_g_r = cv2.resize(face_g, (48, 48))\n",
    "            labels = model.predict(face_g_r.reshape(1, 48, 48, 1)/255.0)\n",
    "            confidence = int(np.max(labels)*100)\n",
    "            label = np.argmax(labels)\n",
    "        frame = cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, str(confidence) + \"% \" + label_map[label], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "    \n",
    "    cv2.imshow(\"video\", frame)\n",
    "    frames += 1\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}